{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important:\n",
    "\n",
    "In order for this code to generate a model usable on the RBPi, you need to have the same versions of Librosa, Keras, and Tensorflow installed. The other package versions may not be significant, but if you are running into errors, check the package versions installable on the RBPi and install the same on the model creating device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "c:\\python3\\lib\\site-packages\\librosa\\core\\audio.py:37: UserWarning: Could not import scikits.samplerate. Falling back to scipy.signal\n",
      "  warnings.warn('Could not import scikits.samplerate. '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "import tensorflow\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from math import trunc\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports all specified audio files, will only import if model.h5 doesn't exist.\n",
    "# If training new model, manually delete old model\n",
    "# Cannot keep training model if model was created previously (for next cell, code can be modified to accept this)\n",
    "# Model closely based on Ajay Halthor's implementation\n",
    "my_file = Path(\"model.h5\")\n",
    "if not my_file.is_file(): \n",
    "    print(\"No model found, creating new model.h...\")\n",
    "    \n",
    "    # Initialize dataset array, source directories and file counts\n",
    "    # Change counts according to own dataset and change split percentage if necessary\n",
    "    D = []\n",
    "    quietwoodpecker_dir = os.path.join(cwd, \"data\\woodpecker_quiet\")\n",
    "    quietCount = 10\n",
    "    woodpecker_dir = os.path.join(cwd, \"data\\woodpecker\")\n",
    "    woodCount = 10\n",
    "    notwoodpecker_dir= os.path.join(cwd, \"data\\\\notwoodpecker\")\n",
    "    notwoodCount = 20\n",
    "    total = quietCount + woodCount + notwoodCount\n",
    "    split= .75\n",
    "    \n",
    "    # Import audio from different sources. In our case there was seperate \"woodepcker\" directories\n",
    "    # Appends data and assigns labels. Change value of counts according to personal dataset size.\n",
    "    count = 0;\n",
    "    for file in os.listdir(quietwoodpecker_dir):\n",
    "        if(count==quietCount):\n",
    "            break\n",
    "        file_name = os.path.join(quietwoodpecker_dir, file)\n",
    "        try:\n",
    "            y, sr = librosa.load(file_name, duration=1)  \n",
    "            ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "            if ps.shape != (128, 44): continue\n",
    "            D.append((ps, 1))\n",
    "            count+=1\n",
    "        except:\n",
    "            print(\"File corrupted:\", file_name)\n",
    "\n",
    "    count = 0;\n",
    "    for file in os.listdir(woodpecker_dir):\n",
    "        if(count==woodCount):\n",
    "            break\n",
    "        file_name = os.path.join(woodpecker_dir, file)\n",
    "        try:\n",
    "            y, sr = librosa.load(file_name, duration=1)  \n",
    "            ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "            if ps.shape != (128, 44): continue\n",
    "            D.append((ps, 1))\n",
    "            count+=1\n",
    "        except:\n",
    "            print(\"File corrupted:\", file_name)\n",
    "\n",
    "    count=0\n",
    "    for file in os.listdir(notwoodpecker_dir):\n",
    "        if(count==notwoodCount):\n",
    "            break\n",
    "        file_name = os.path.join(notwoodpecker_dir, file)\n",
    "        try:\n",
    "            y, sr = librosa.load(file_name, duration=1)  \n",
    "            ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "            if ps.shape != (128, 44): continue\n",
    "            D.append((ps, 0))\n",
    "            count+=1\n",
    "        except:\n",
    "            print(\"File corrupted:\", file_name)\n",
    "            \n",
    "    print(\"All audio has been imported...\")\n",
    "    \n",
    "    #Shuffles the dataset and splits training and test set\n",
    "    dataset = D\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    train = dataset[:trunc(total*split)]\n",
    "    test = dataset[trunc(total*split):]\n",
    "\n",
    "    X_train, y_train = zip(*train)\n",
    "    X_test, y_test = zip(*test)\n",
    "\n",
    "    # Reshape for CNN input\n",
    "    X_train = np.array([x.reshape( (128, 44, 1) ) for x in X_train])\n",
    "    X_test = np.array([x.reshape( (128, 44, 1) ) for x in X_test])\n",
    "\n",
    "    # One-Hot encoding for classes\n",
    "    y_train = np.array(to_categorical(y_train, 2))\n",
    "    y_test = np.array(to_categorical(y_test, 2))\n",
    "    \n",
    "    # Layer creation for CNN\n",
    "    model = Sequential()\n",
    "    input_shape=(128, 44, 1)\n",
    "\n",
    "    model.add(Convolution2D(24, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(48, (5, 5), padding=\"valid\"))\n",
    "    model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(48, (5, 5), padding=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    # Fit model to data and evaluate, change epochs if necessary\n",
    "    model.fit(x=X_train, y=y_train, epochs=2, batch_size=128, validation_data= (X_test, y_test))\n",
    "\n",
    "    score = model.evaluate(x=X_test,y=y_test)\n",
    "    model.save('model.h5')\n",
    "    print(\"Model created and saved...\")\n",
    "else:\n",
    "    print(\"Loading model from model.h5...\")\n",
    "    model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply test a file that is NOT part of the original dataset, just change path in next line\n",
    "test_file = os.path.join(cwd, \"data\\\\testing\\\\pecker.mp3\")\n",
    "\n",
    "y, sr = librosa.load(test_file, duration=1)  \n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "test = np.array([ps.reshape( (128, 44, 1) )])\n",
    "\n",
    "# This assumes acceptance rate of 50%, this may be djusted to how the device interprets audio\n",
    "# For example,if most non-woodpecker audio falls under 5% and introducing woodpecker audio brings prediction up to 15%,\n",
    "# you may want to change the threshold to 10%. This should also be done for the device code as well.\n",
    "(notWood, Wood) = model.predict(test)[0]\n",
    "label = \"Woodpecker\" if Wood > notWood else \"Not Woodpecker\"\n",
    "proba = Wood if Wood > notWood else notWood\n",
    "label = \"{}: {:.2f}%\".format(label, proba * 100)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if getting poor results in previous cell. Will keep fitting data to obtain higher accuracy\n",
    "# Warning, may overfit data, cannot be done for imported models\n",
    "model.fit(x=X_train, y=y_train, epochs=1, batch_size=128, validation_data= (X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
